"""
Unified training script for all Unimodal Multilayer Perceptrons (MLPs).

Dynamically reads the optimal hyperparameters generated by Optuna,
constructs the modality-specific MLP architecture, trains the model
with Early Stopping, and evaluates it on the test set.

Usage:
    python -m src.models.unimodal.mlp.train_unimodal_mlp --modality ehr
"""

import argparse
import json
import logging
import sys
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from torch.utils.tensorboard import SummaryWriter

from src.utils.config import Config
from src.utils.evaluation import (
    compute_metrics,
    load_embeddings,
    log_metrics_to_tensorboard,
    print_metrics,
    save_metrics,
    save_predictions,
)

logger = logging.getLogger(__name__)

NUM_EPOCHS = 100
PATIENCE = 15
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def get_modality_paths(modality: str):
    base_results = Config.RESULTS_DIR / modality

    if modality == "ehr":
        data_dir = Config.EHR_EMBEDDINGS_DIR
        model_dir = Config.EHR_MLP_MODEL_DIR
    elif modality == "ecg":
        data_dir = Config.ECG_EMBEDDINGS_DIR
        model_dir = Config.ECG_MLP_MODEL_DIR
    elif modality == "cxr_img":
        data_dir = Config.CXR_IMG_EMBEDDINGS_DIR
        model_dir = Config.CXR_IMG_MLP_MODEL_DIR
    elif modality == "cxr_txt":
        data_dir = Config.CXR_TXT_EMBEDDINGS_DIR
        model_dir = Config.CXR_TXT_MLP_MODEL_DIR
    else:
        raise ValueError(f"Unknown modality: {modality}")

    results_dir = base_results / "mlp"
    tb_dir = Config.TENSORBOARD_LOG_DIR / modality / "mlp"
    tuning_file = base_results / "tuning" / "best_hyperparameters.json"

    paths = {
        "data_dir": data_dir,
        "model_save_path": model_dir / f"best_{modality}_mlp.pt",
        "tuning_file": tuning_file,
        "metrics_save_path": results_dir / "test_metrics_mlp.json",
        "val_metrics_save_path": results_dir / "val_metrics_mlp.json",
        "predictions_save_path": results_dir / "test_predictions_mlp.csv",
        "tb_dir": tb_dir,
    }

    model_dir.mkdir(parents=True, exist_ok=True)
    results_dir.mkdir(parents=True, exist_ok=True)
    tb_dir.mkdir(parents=True, exist_ok=True)
    return paths


# ==========================================
# DYNAMIC MODEL
# ==========================================
class DynamicModalityMLP(nn.Module):
    def __init__(self, input_dim: int, config: dict):
        super().__init__()

        hidden_1 = config["hidden_dim_1"]
        hidden_2 = config["hidden_dim_2"]
        dropout_rate = config.get("dropout_rate", 0.0)
        norm_type = config.get("norm_type", "layer")
        use_dropout = config.get("use_dropout", False)
        use_input_norm = config.get("use_input_norm", True)
        activation_name = config.get("activation", "GELU")

        activation_layer = nn.ReLU() if activation_name == "ReLU" else nn.GELU()

        # ── DYNAMIC PROJECTION TO COMMON DIMENSION (768) ──
        self.projection = None
        current_dim = input_dim

        if input_dim != 768:
            self.projection = nn.Linear(input_dim, 768)
            current_dim = 768

        layers = []

        # Note: We now use current_dim instead of input_dim
        if use_input_norm:
            layers.append(nn.LayerNorm(current_dim))

        layers.append(nn.Linear(current_dim, hidden_1))
        layers.append(
            nn.BatchNorm1d(hidden_1) if norm_type == "batch" else nn.LayerNorm(hidden_1)
        )
        layers.append(activation_layer)
        if use_dropout:
            layers.append(nn.Dropout(dropout_rate))

        layers.append(nn.Linear(hidden_1, hidden_2))
        layers.append(
            nn.BatchNorm1d(hidden_2) if norm_type == "batch" else nn.LayerNorm(hidden_2)
        )
        layers.append(activation_layer)
        if use_dropout:
            layers.append(nn.Dropout(dropout_rate))

        layers.append(nn.Linear(hidden_2, 1))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        if self.projection is not None:
            x = self.projection(x)
        return self.network(x)


# ==========================================
# HELPER FUNCTIONS
# ==========================================
def create_dataloader(
    X: np.ndarray, y: np.ndarray, batch_size: int, shuffle: bool
) -> DataLoader:
    X_tensor = torch.tensor(X, dtype=torch.float32)
    y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)
    dataset = TensorDataset(X_tensor, y_tensor)

    # Enforce strict reproducibility for shuffling
    g = torch.Generator()
    g.manual_seed(42)

    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        generator=g if shuffle else None,
    )


def evaluate_model(
    model: nn.Module, dataloader: DataLoader
) -> tuple[np.ndarray, np.ndarray, float]:
    model.eval()
    criterion = nn.BCEWithLogitsLoss()
    total_loss = 0.0
    all_probs, all_targets = [], []

    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)
            logits = model(inputs)
            loss = criterion(logits, targets)
            total_loss += loss.item() * inputs.size(0)
            probs = torch.sigmoid(logits).cpu().numpy()
            all_probs.extend(probs)
            all_targets.extend(targets.cpu().numpy())

    avg_loss = total_loss / len(dataloader.dataset)
    return np.array(all_targets).flatten(), np.array(all_probs).flatten(), avg_loss


# ==========================================
# MAIN EXECUTION
# ==========================================
def main():
    Config.setup_logging()
    Config.set_seed(42)

    parser = argparse.ArgumentParser(description="Train a Unimodal MLP dynamically.")
    parser.add_argument(
        "--modality",
        type=str,
        required=True,
        choices=["ehr", "ecg", "cxr_img", "cxr_txt"],
    )
    args = parser.parse_args()

    modality = args.modality
    paths = get_modality_paths(modality)

    logger.info(f"=== Starting Training Pipeline for {modality.upper()} ===")

    if not paths["tuning_file"].exists():
        logger.error(f"Tuning file not found at {paths['tuning_file']}.")
        sys.exit(1)

    with open(paths["tuning_file"], "r") as f:
        tuning_data = json.load(f)
    best_params = tuning_data["params"]
    logger.info(f"Loaded dynamic hyperparameters: {best_params}")

    batch_size = best_params.get("batch_size", 128)

    writer = SummaryWriter(log_dir=str(paths["tb_dir"]))

    logger.info("--- Loading Data ---")
    data_dir = paths["data_dir"]
    X_train, y_train, _ = load_embeddings(data_dir / "train_embeddings.pt")
    X_val, y_val, _ = load_embeddings(data_dir / "valid_embeddings.pt")
    X_test, y_test, test_ids = load_embeddings(data_dir / "test_embeddings.pt")

    train_loader = create_dataloader(X_train, y_train, batch_size, shuffle=True)
    val_loader = create_dataloader(X_val, y_val, batch_size, shuffle=False)
    test_loader = create_dataloader(X_test, y_test, batch_size, shuffle=False)

    logger.info(f"--- Initializing Dynamic Model on {DEVICE} ---")
    input_dim = X_train.shape[1]
    model = DynamicModalityMLP(input_dim=input_dim, config=best_params).to(DEVICE)

    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.AdamW(
        model.parameters(),
        lr=best_params["lr"],
        weight_decay=best_params["weight_decay"],
    )

    logger.info("--- Starting Training ---")
    best_val_auroc = 0.0
    epochs_without_improvement = 0

    for epoch in range(1, NUM_EPOCHS + 1):
        model.train()
        train_loss = 0.0

        for inputs, targets in train_loader:
            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)
            optimizer.zero_grad()
            logits = model(inputs)
            loss = criterion(logits, targets)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)

        train_loss /= len(train_loader.dataset)

        val_true, val_prob, val_loss = evaluate_model(model, val_loader)
        val_metrics = compute_metrics(val_true, val_prob)

        logger.info(
            f"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | "
            f"Val Loss: {val_loss:.4f} | Val AUROC: {val_metrics['auroc']:.4f}"
        )

        writer.add_scalar("Loss/train", train_loss, epoch)
        writer.add_scalar("Loss/val", val_loss, epoch)
        log_metrics_to_tensorboard(writer, val_metrics, epoch, prefix="Val")

        if val_metrics["auroc"] > best_val_auroc:
            best_val_auroc = val_metrics["auroc"]
            epochs_without_improvement = 0
            torch.save(model.state_dict(), paths["model_save_path"])
            logger.info(f"  -> Best model saved! (AUROC: {best_val_auroc:.4f})")
        else:
            epochs_without_improvement += 1
            if epochs_without_improvement >= PATIENCE:
                logger.warning(f"Early stopping triggered at epoch {epoch}")
                break

    logger.info("--- Evaluating Best Model on Test Set ---")
    model.load_state_dict(torch.load(paths["model_save_path"]))

    val_true_final, val_prob_final, _ = evaluate_model(model, val_loader)
    val_metrics_final = compute_metrics(val_true_final, val_prob_final)
    save_metrics(paths["val_metrics_save_path"], val_metrics_final)

    test_true, test_prob, _ = evaluate_model(model, test_loader)
    test_pred = (test_prob >= 0.5).astype(int)

    test_metrics = compute_metrics(test_true, test_prob)
    print_metrics(test_metrics, name=f"{modality.upper()} TEST SET (Dynamic MLP)")

    log_metrics_to_tensorboard(writer, test_metrics, global_step=0, prefix="Test")
    writer.close()

    save_metrics(paths["metrics_save_path"], test_metrics)
    save_predictions(
        paths["predictions_save_path"], test_ids, test_true, test_prob, test_pred
    )

    logger.info(f"=== {modality.upper()} MLP Training Pipeline Complete! ===")


if __name__ == "__main__":
    main()
